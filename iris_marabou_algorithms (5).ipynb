{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_X033oPFf-0",
        "outputId": "e8418a30-25b3-41fe-a250-eb5dba7bcf1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.7)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.1\n",
            "Collecting onnx2pytorch\n",
            "  Downloading onnx2pytorch-0.4.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from onnx2pytorch) (2.2.1+cu121)\n",
            "Requirement already satisfied: onnx>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from onnx2pytorch) (1.15.0)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from onnx2pytorch) (0.17.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx>=1.6.0->onnx2pytorch) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.6.0->onnx2pytorch) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->onnx2pytorch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->onnx2pytorch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->onnx2pytorch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->onnx2pytorch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->onnx2pytorch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->onnx2pytorch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->onnx2pytorch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->onnx2pytorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m87.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.9.0->onnx2pytorch) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->onnx2pytorch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->onnx2pytorch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, onnx2pytorch\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105 onnx2pytorch-0.4.1\n",
            "Collecting maraboupy\n",
            "  Downloading maraboupy-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: maraboupy\n",
            "Successfully installed maraboupy-1.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx\n",
        "!pip install onnxruntime\n",
        "!pip install onnx2pytorch\n",
        "!pip install maraboupy\n",
        "#!pip install tensorflow[and-cuda]==2.13.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import the model here. Optionally, import the relu states."
      ],
      "metadata": {
        "id": "cw1rDOqlcLRK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import onnx\n",
        "from onnx2pytorch import ConvertModel\n",
        "folder_path = '/content/drive/My Drive/oopsla_nap'\n",
        "iris_onnx_path = folder_path + '/iris_model_60.onnx'  # Adjust file extension if needed\n",
        "PATTERN_PATH = folder_path + '/relu_states.txt'  # Adjust file extension if needed\n",
        "\n",
        "# iris_onnx_path = 'iris_model_60.onnx'  # Adjust file extension if needed\n",
        "# PATTERN_PATH = 'relu_states_allen.txt'  # Adjust file extension if needed\n"
      ],
      "metadata": {
        "id": "1aUNRfJ8S6CG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "412bfb80-ece9-43da-9a58-2fbc2cf68c4b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get the iris dataset, hook the activation to the relu layers \"relu1\", \"relu2\", \"relu3\".\n",
        "# Find the states and save it as a dictionary. Each label is a key. Each value is another dict where the neuron_id is a key and the values are are the activations of different inputs. So the dictionary \"states\" is in the shape: {Label: {neuron_id: [list of length len(inputs)]}}.\n",
        "#The function \"convert_dict_to_list\" converts the values of each label key to a list of list where the row is number of relus and column is number of inputs.\n",
        "#In the next cell, the states are saved as list directly where the row is number of inputs and column is number of relus.\n"
      ],
      "metadata": {
        "id": "bZFUxzLHcUQ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "s0A9rv3hU5HN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnx2pytorch import ConvertModel\n",
        "\n",
        "\n",
        "onnx_model = onnx.load(iris_onnx_path)\n",
        "model = ConvertModel(onnx_model)\n",
        "\n",
        "activations = {}\n",
        "\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activations[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "i=1\n",
        "# Assuming the ReLU layers are named similarly to your PyTorch model, you can add hooks like this\n",
        "for name, layer in model.named_modules():\n",
        "    if isinstance(layer, torch.nn.ReLU):\n",
        "        # Register the hook\n",
        "        layer.register_forward_hook(get_activation(f'relu{i}'))\n",
        "        i=i+1\n",
        "\n",
        "import json\n",
        "states={}\n",
        "for i in range(3):\n",
        "  states[i]={}\n",
        "\n",
        "with torch.no_grad():\n",
        "  for neuron in range(60):\n",
        "    for idx, (inputs, labels) in enumerate(train_loader):\n",
        "      for i,t in zip(inputs,labels):\n",
        "        t=t.item()\n",
        "        outputs = model(i.unsqueeze(0))\n",
        "        out=activations[f'relu{(neuron//20)+1}'][:,neuron%20].tolist()[0]\n",
        "        if not neuron in states[t]:\n",
        "          states[t][neuron]=[]\n",
        "        states[t][neuron].append(out)\n",
        "\n",
        "def convert_dict_to_list(states): #coverts the values of each label to a list. states[label]=list of len(inputs) x len(number of relus)\n",
        "  for label in states:\n",
        "    label_list=[]\n",
        "    for neuron in states[label]:\n",
        "      label_list.append(states[label][neuron])\n",
        "    states[label]=label_list\n",
        "  return states\n",
        "\n",
        "# len(STABLE_PATTERNS[0])#60 relus\n",
        "# len(STABLE_PATTERNS[0][0])#40 inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZBDJtRwU7-Q",
        "outputId": "4bb27ee3-e499-4130-f85f-3eb13e5e363b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/onnx2pytorch/convert/layer.py:30: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
            "  layer.weight.data = torch.from_numpy(numpy_helper.to_array(weight))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  for neuron in range(60):\n",
        "    for idx, (inputs, labels) in enumerate(train_loader):\n",
        "      for i,t in zip(inputs,labels):\n",
        "        t=t.item()\n",
        "        outputs = model(i.unsqueeze(0))\n",
        "        out=activations[f'relu{(neuron//20)+1}'][:,neuron%20].tolist()[0]\n",
        "        if not neuron in states[t]:\n",
        "          states[t][neuron]=[]\n",
        "        states[t][neuron].append(out)"
      ],
      "metadata": {
        "id": "ekx7rNYFdQZ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=X_train_tensor[0]\n",
        "i=1\n",
        "j=1\n",
        "layers={}\n",
        "# Assuming the ReLU layers are named similarly to your PyTorch model, you can add hooks like this\n",
        "for name, layer in model.named_modules():\n",
        "  if isinstance(layer, torch.nn.ReLU):\n",
        "    # Register the hook\n",
        "    layers[f'relu{i}']=layer\n",
        "    i=i+1\n",
        "  if isinstance(layer, torch.nn.Linear):\n",
        "    # Register the hook\n",
        "    layers[f'linear{i}']=layer\n",
        "    j=j+1\n",
        "layers\n",
        "\n",
        "def get_activations(input):\n",
        "  layer1=model.Relu_result(model.Gemm_input(input.unsqueeze(0)))\n",
        "  layer2=layers['relu2'](layers['linear2'](layer1))\n",
        "  layer3=layers['relu3'](layers['linear3'](layer2))\n",
        "  layer4=model.Gemm_15(layer3)\n",
        "  all_relus = torch.concat([layer1[0].detach(),layer2[0].detach(),layer3[0].detach()])\n",
        "  return all_relus\n",
        "# ConvertModel(\n",
        "#   (Gemm_input): Linear(in_features=4, out_features=20, bias=True)\n",
        "#   (Relu_result): ReLU(inplace=True)\n",
        "#   (Gemm_input.3): Linear(in_features=20, out_features=20, bias=True)\n",
        "#   (Relu_result.3): ReLU(inplace=True)\n",
        "#   (Gemm_input.7): Linear(in_features=20, out_features=20, bias=True)\n",
        "#   (Relu_result.7): ReLU(inplace=True)\n",
        "#   (Gemm_15): Linear(in_features=20, out_features=3, bias=True)\n",
        "# )"
      ],
      "metadata": {
        "id": "CjDzTbGrti-l"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset_nap=label_naps[0].copy()#48, 55, 54\n",
        "for i in range(45):\n",
        "  subset_nap[i]='*'\n",
        "for i in range(50,60):\n",
        "  subset_nap[i]='*'\n",
        "subset_nap.count(0)\n"
      ],
      "metadata": {
        "id": "96ICZE5yg-Dx",
        "outputId": "1523bbce-6247-416b-b0c2-c76fb6c26389",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = 0\n",
        "def get_class_of_label(l):\n",
        "    ls = []\n",
        "    for input, label in train_dataset:\n",
        "        if label == l: ls.append(input)\n",
        "    return ls\n",
        "\n",
        "class_0 = get_class_of_label(label)\n",
        "len(class_0)"
      ],
      "metadata": {
        "id": "q0HehmLDs6K5",
        "outputId": "79c4ddf3-571b-4d48-c3d0-86f91f30e6ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reduced_nap(indices, label):\n",
        "    reduced_nap = []\n",
        "    for i in indices:\n",
        "        reduced_nap.append((i, label_naps[label][i]))\n",
        "    return reduced_nap\n",
        "\n",
        "def nap_tup(nap):\n",
        "    ls = []\n",
        "    for i, if_fire in enumerate(nap):\n",
        "        if isinstance(if_fire, str): continue\n",
        "        ls.append((i, if_fire))\n",
        "    return ls\n",
        "\n",
        "\n",
        "indices = [48]\n",
        "label = 0\n",
        "reduced_nap = get_reduced_nap(indices, label)\n",
        "reduced_nap"
      ],
      "metadata": {
        "id": "on8KpWEr2L8Q",
        "outputId": "01e48bfc-011f-46a4-ee9d-07db8b4f8669",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(48, 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label = 1\n",
        "class_0 = get_class_of_label(label)\n",
        "class_0_nap = []\n",
        "indices = [55]\n",
        "reduced_nap = get_reduced_nap(indices, label)\n",
        "\n",
        "for input in class_0:\n",
        "    model(input.unsqueeze(0))\n",
        "    sat = True\n",
        "    for index, if_fire in reduced_nap:\n",
        "        if not sat: continue\n",
        "\n",
        "        relu_value = activations[f'relu{(index//20)+1}'][:,index%20].tolist()[0]\n",
        "        # print(if_fire, relu_value)\n",
        "        if if_fire and relu_value > 0:\n",
        "            sat = True\n",
        "        elif not if_fire and relu_value <= 0:\n",
        "            sat = True\n",
        "        else: sat = False\n",
        "    if sat:\n",
        "        class_0_nap.append(input)\n",
        "        print(\"Added!\")\n",
        "len(class_0_nap)"
      ],
      "metadata": {
        "id": "7m1II8eI2Tp-",
        "outputId": "1ed9199e-f950-4bf3-ef5a-484a913ddfed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added!\n",
            "Added!\n",
            "Added!\n",
            "Added!\n",
            "Added!\n",
            "Added!\n",
            "Added!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "match=0\n",
        "temp=states[0]\n",
        "temp1=label_naps[0]\n",
        "for i in range(40):\n",
        "  print(i)\n",
        "  flag=True\n",
        "  for neuron in range(60):\n",
        "    nap=temp1[neuron]\n",
        "    if nap==0:\n",
        "      if not temp[neuron][i]==0.0:\n",
        "        flag=False\n",
        "      #print(f\"nap should be 0, actual input: {temp[neuron][i]}\")\n",
        "    if nap==1:\n",
        "      if not temp[neuron][i]>0:\n",
        "        flag=False\n",
        "      #print(f\"nap should be 1, actual input: {temp[neuron][i]}\")\n",
        "  if flag:\n",
        "    print(\"match\")\n",
        "    match+=1\n",
        "print(f\"matched {match}\")"
      ],
      "metadata": {
        "id": "Rw4UIxQ2qENy",
        "outputId": "d8fee264-81b6-4d61-ba83-c58df6f54ecc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "match\n",
            "1\n",
            "match\n",
            "2\n",
            "match\n",
            "3\n",
            "match\n",
            "4\n",
            "5\n",
            "6\n",
            "match\n",
            "7\n",
            "8\n",
            "match\n",
            "9\n",
            "match\n",
            "10\n",
            "match\n",
            "11\n",
            "match\n",
            "12\n",
            "13\n",
            "match\n",
            "14\n",
            "match\n",
            "15\n",
            "match\n",
            "16\n",
            "17\n",
            "match\n",
            "18\n",
            "match\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "match\n",
            "23\n",
            "24\n",
            "match\n",
            "25\n",
            "match\n",
            "26\n",
            "match\n",
            "27\n",
            "match\n",
            "28\n",
            "match\n",
            "29\n",
            "match\n",
            "30\n",
            "match\n",
            "31\n",
            "32\n",
            "match\n",
            "33\n",
            "match\n",
            "34\n",
            "match\n",
            "35\n",
            "match\n",
            "36\n",
            "match\n",
            "37\n",
            "match\n",
            "38\n",
            "39\n",
            "match\n",
            "matched 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_naps[0]"
      ],
      "metadata": {
        "id": "YCRXj8YplkkD",
        "outputId": "a42a47c3-93ee-4967-bf2a-621b48b4ea2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 1,\n",
              " '*',\n",
              " 1,\n",
              " 0,\n",
              " '*',\n",
              " '*',\n",
              " 0,\n",
              " 1,\n",
              " '*',\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " '*',\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " '*',\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 1,\n",
              " 0,\n",
              " 0,\n",
              " 1,\n",
              " 0]"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=0\n",
        "neuron=0\n",
        "match=0\n",
        "index=-1\n",
        "for input, target in zip(X_train_tensor, y_train_tensor):\n",
        "  if target==t:\n",
        "    index+=1\n",
        "    relus=get_activations(input)\n",
        "    flag=True\n",
        "    for neuron in range(60):\n",
        "      if label_naps[0][neuron]==0:\n",
        "        if not relus[neuron]==0:\n",
        "          flag=False\n",
        "      if label_naps[0][neuron]==1:\n",
        "        if not relus[neuron]>0:\n",
        "          flag=False\n",
        "    if flag:\n",
        "      match+=1\n",
        "      print(index)\n",
        "print(match)"
      ],
      "metadata": {
        "id": "xW5a97RuyGq-",
        "outputId": "0a1f9876-29c2-4bf6-8ca4-2e2413c6fbd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=0\n",
        "neuron=0\n",
        "match=0\n",
        "index=-1\n",
        "for input, target in zip(X_train_tensor, y_train_tensor):\n",
        "  if target==t:\n",
        "    index+=1\n",
        "    model(input.unsqueeze(0))\n",
        "    #print(activations\n",
        "    #relus=get_activations(input)\n",
        "    flag=True\n",
        "    for neuron in range(60):\n",
        "      if label_naps[0][neuron]==0:\n",
        "        if not activations[f'relu{(neuron//20)+1}'][:,neuron%20].tolist()[0]==0:\n",
        "          flag=False\n",
        "      if label_naps[0][neuron]==1:\n",
        "        if not activations[f'relu{(neuron//20)+1}'][:,neuron%20].tolist()[0]>0:\n",
        "          flag=False\n",
        "    if flag:\n",
        "      match+=1\n",
        "      print(f\"added {index}\")\n",
        "\n",
        "\n",
        "print(match)\n",
        "    #print(activations[f'relu{(neuron//20)+1}'][:,neuron%20].tolist()[0])\n"
      ],
      "metadata": {
        "id": "QPqe5CWmek6a",
        "outputId": "057ffd4d-8595-4b22-f67c-c81799565e45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "added 0\n",
            "added 2\n",
            "added 3\n",
            "added 4\n",
            "added 5\n",
            "added 6\n",
            "added 7\n",
            "added 8\n",
            "added 9\n",
            "added 10\n",
            "added 11\n",
            "added 12\n",
            "added 13\n",
            "added 15\n",
            "added 16\n",
            "added 17\n",
            "added 18\n",
            "added 19\n",
            "added 20\n",
            "added 21\n",
            "added 22\n",
            "added 23\n",
            "added 24\n",
            "added 26\n",
            "added 27\n",
            "added 28\n",
            "added 29\n",
            "added 30\n",
            "added 31\n",
            "added 32\n",
            "added 34\n",
            "added 35\n",
            "added 36\n",
            "added 37\n",
            "added 38\n",
            "added 39\n",
            "36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "activations[\"relu1\"][0][0].tolist()"
      ],
      "metadata": {
        "id": "gfO1aGBmP11K",
        "outputId": "cdef8055-08eb-4c24-a283-a231fc1b0dce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5013340711593628"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "find states as list (row: inputs, column: relus)\n"
      ],
      "metadata": {
        "id": "pZ--e7zx4kAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import json\n",
        "\n",
        "# states={}\n",
        "# for i in range(3):\n",
        "#   states[i]=[] #{}\n",
        "\n",
        "# with torch.no_grad():\n",
        "#   for idx, (inputs, labels) in enumerate(train_loader):\n",
        "#     for i,t in zip(inputs,labels):\n",
        "#       relu_states=[]\n",
        "#       t=t.item()\n",
        "#       outputs = model(i.unsqueeze(0))\n",
        "#       for neuron in range(60):\n",
        "#         out=activations[f'relu{(neuron//20)+1}'][:,neuron%20].tolist()[0]\n",
        "#         relu_states.append(out)\n",
        "#         # if not t in states:\n",
        "#         #   states[t]=[]\n",
        "#       states[t].append(relu_states)\n",
        "\n",
        "# with open(f\"iris_relu_states\", \"w\") as fp:\n",
        "#   json.dump(states, fp)\n",
        "# states"
      ],
      "metadata": {
        "id": "JncOuKutVJ3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RZmiALnbf9Hd",
        "outputId": "935d4b95-4716-457a-9552-ec50baed4e4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "from maraboupy import Marabou, MarabouCore, MarabouUtils\n",
        "import json\n",
        "from typing import Tuple, List\n",
        "import logging\n",
        "import pandas\n",
        "\n",
        "def init_network():\n",
        "  network = Marabou.read_onnx(iris_onnx_path)\n",
        "  return network\n",
        "\n",
        "EPSILON = 0.5\n",
        "MAX_TIME = 30 #in seconds\n",
        "M_OPTIONS: MarabouCore.Options = Marabou.createOptions(verbosity=1, numWorkers=1, timeoutInSeconds=MAX_TIME)\n",
        "\n",
        "def convert_keys_to_int(x):\n",
        "    if isinstance(x, dict):\n",
        "        return {int(k) if k.isdigit() else k: convert_keys_to_int(v) for k, v in x.items()}\n",
        "    return x\n",
        "\n",
        "def parse_raw_idx(raw_idx: int) -> Tuple[int, int, int]:\n",
        "    n_relus = 20\n",
        "    offset = 7\n",
        "    layer = raw_idx // n_relus\n",
        "    idx = raw_idx % n_relus\n",
        "    marabou_idx = 2*n_relus*layer + idx + offset\n",
        "    return layer, idx, marabou_idx\n",
        "\n",
        "loc = 0.5\n",
        "radus = 0.5\n",
        "non_restricted_dim = []"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "if importing a existing relu states file, uncomment the following cell. Otherwise, change the name so that ***STABLE_PATTERNS=states. *** Because later code uses STABLE_PATTERNS as the variable name for the relu activations to determine whether it's open or closed."
      ],
      "metadata": {
        "id": "D6TZRzC9eVmG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(PATTERN_PATH, \"r\") as f:\n",
        "  STABLE_PATTERNS = json.load(f)\n",
        "  STABLE_PATTERNS=convert_keys_to_int(STABLE_PATTERNS)"
      ],
      "metadata": {
        "id": "8TAib_4ReTvQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STABLE_PATTERNS=states"
      ],
      "metadata": {
        "id": "PzVHGvYqia1T"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "find nap given states as dict. Can be commented out if not necessary. But basically it takes the activations and delta and convert it to a nap for eachlabel in the form of [0,1,0, ... *, 0,1]"
      ],
      "metadata": {
        "id": "gtte6_bO6dCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "STABLE_PATTERNS=states\n",
        "delta=0.9"
      ],
      "metadata": {
        "id": "07t3HYdIeQIF"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STABLE_PATTERNS[0][2]"
      ],
      "metadata": {
        "id": "pR2A4OgemhrV",
        "outputId": "11289f39-7934-45c5-fe41-8ae69cfdf481",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0,\n",
              " 0.2269478440284729,\n",
              " 0.12910127639770508,\n",
              " 0.04803657531738281,\n",
              " 0.0,\n",
              " 0.1212189793586731,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.4165295958518982,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.37415599822998047,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.014735877513885498,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.0,\n",
              " 0.6656107306480408]"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "STABLE_PATTERNS=states#[label][relus].count(0)"
      ],
      "metadata": {
        "id": "zktDTU3RmGMb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_naps={}\n",
        "delta=0.9\n",
        "for label in STABLE_PATTERNS:\n",
        "  for relus in STABLE_PATTERNS[label]:\n",
        "    if ((len(STABLE_PATTERNS[label][relus])-STABLE_PATTERNS[label][relus].count(0))/len(STABLE_PATTERNS[label][relus]))>=delta:\n",
        "      if not label in label_naps:\n",
        "        label_naps[label]=[]\n",
        "      label_naps[label].append(1)\n",
        "    elif ((len(STABLE_PATTERNS[label][relus])-STABLE_PATTERNS[label][relus].count(0))/len(STABLE_PATTERNS[label][relus])) <=(1-delta):\n",
        "      if not label in label_naps:\n",
        "        label_naps[label]=[]\n",
        "      label_naps[label].append(0)\n",
        "    else:\n",
        "      if not label in label_naps:\n",
        "        label_naps[label]=[]\n",
        "      label_naps[label].append('*')\n",
        "label_naps\n",
        "\n",
        "for label,values in label_naps.items():\n",
        "  print(f\"label {label} nap: {values.count(1)+values.count(0)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqrlY7y7ZM6W",
        "outputId": "36b1996e-751b-4774-e63e-43740fa6f1ef"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label 0 nap: 54\n",
            "label 1 nap: 41\n",
            "label 2 nap: 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_naps[0][48]"
      ],
      "metadata": {
        "id": "OivwbSlOnD2B",
        "outputId": "20d58b66-7961-407f-93f4-fe918f6e0e28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "marabou algorithms. Can be run sequentially."
      ],
      "metadata": {
        "id": "rU3w29GJ76K_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def add_relu_constraints(network: Marabou.MarabouNetworkNNet, label_states, a=None)->Marabou.MarabouNetworkNNet:\n",
        "    \"\"\"\n",
        "    Add stable relus constraints to the Marabou network\n",
        "    \"\"\"\n",
        "    if a:\n",
        "      for neuron,values in label_states.items(): #everything\n",
        "        if a[neuron]==1: #include this relu\n",
        "          layer, idx, marabou_idx = parse_raw_idx(neuron)\n",
        "          #print(f'{neuron}: {values}')\n",
        "          if (len(values)-values.count(0))/len(values) >= delta: #len(X_train)*0.5:  len(values)\n",
        "              constraint = MarabouUtils.Equation(MarabouCore.Equation.GE)\n",
        "              constraint.addAddend(1, marabou_idx)\n",
        "              constraint.setScalar(0.001)\n",
        "              network.addEquation(constraint)\n",
        "          elif (len(values)-values.count(0))/len(values) <= 1-delta:\n",
        "              constraint = MarabouUtils.Equation(MarabouCore.Equation.LE)\n",
        "              constraint.addAddend(1, marabou_idx)\n",
        "              constraint.setScalar(-0.001)\n",
        "              network.addEquation(constraint)\n",
        "\n",
        "    else:\n",
        "      for neuron,values in label_states.items():\n",
        "          layer, idx, marabou_idx = parse_raw_idx(neuron)\n",
        "          #print(f'{neuron}: {values}')\n",
        "          if values.count(0) > len(values)*0.5: #len(X_train)*0.5:  len(values)\n",
        "              constraint = MarabouUtils.Equation(MarabouCore.Equation.LE)\n",
        "              constraint.addAddend(1, marabou_idx)\n",
        "              constraint.setScalar(-0.001)\n",
        "          else:\n",
        "              constraint = MarabouUtils.Equation(MarabouCore.Equation.GE)\n",
        "              constraint.addAddend(1, marabou_idx)\n",
        "              constraint.setScalar(0.001)\n",
        "          network.addEquation(constraint)\n",
        "        # import pdb;pdb.set_trace()\n",
        "\n",
        "    return network\n",
        "\n",
        "\n",
        "\n",
        "def check_pattern(label_states, label: int, other_label: int, a=None)->Tuple[str, int]: #relu_check_list: List[int], relu_val: List[int]\n",
        "    \"\"\"\n",
        "    In ACAS, the prediction is the label with smallest value.\n",
        "    So we check that label - other_label < 0 forall input\n",
        "    by finding assignments for label - other_label >=0\n",
        "    \"\"\"\n",
        "    print(\"--------CHECK PATTERN: output_{} is always less than output_{} ? --------\".format(label, other_label))\n",
        "    network = init_network()\n",
        "    network = add_relu_constraints(network, label_states,a) #previously commented out??\n",
        "    offset = network.outputVars[0][0][0]\n",
        "    for i in range(4):\n",
        "      network.setLowerBound(i, 0)\n",
        "      network.setUpperBound(i, 1)\n",
        "    #add output constraint\n",
        "    constraint = MarabouUtils.Equation(MarabouCore.Equation.GE)\n",
        "    constraint.addAddend(1, other_label+offset)\n",
        "    constraint.addAddend(-1, label+offset)\n",
        "    constraint.setScalar(0.001)\n",
        "    network.addEquation(constraint)\n",
        "\n",
        "\n",
        "    #add additional bounds here\n",
        "    exit_code: str\n",
        "    #import pdb;pdb.set_trace()\n",
        "    try:\n",
        "      exit_code, vals, stats = network.solve(options=M_OPTIONS)\n",
        "    except Exception as e:\n",
        "      print(f\"exception {e}\")\n",
        "      exit_code = \"error\"\n",
        "      running_time=-1\n",
        "\n",
        "    running_time:int = stats.getTotalTimeInMicro()\n",
        "\n",
        "    return exit_code, running_time\n",
        "\n",
        "def main():\n",
        "    res = [[-1.]*3 for i in range(3)]\n",
        "    # print(res)\n",
        "    for label in range(3):\n",
        "        print(f\"For label {label}, check if its stable RELU pattern guarantees the output\")\n",
        "        for other_label in range(3):#range(10):\n",
        "            if other_label == int(label):\n",
        "                continue\n",
        "            # relu_check_list = STABLE_PATTERNS[label][\"stable_idx\"]\n",
        "            # relu_val = STABLE_PATTERNS[label][\"val\"]\n",
        "            exit_code, running_time = check_pattern(STABLE_PATTERNS[label], label=int(label), other_label = other_label)\n",
        "            if exit_code==\"sat\":\n",
        "                res[int(label)][other_label] = \"SAT:{}\".format(running_time/10**6)\n",
        "                break\n",
        "            elif exit_code==\"unsat\":\n",
        "                res[int(label)][other_label] = \"UNS:{}\".format(running_time/10**6)\n",
        "\n",
        "            else:\n",
        "                res[int(label)][other_label] = exit_code\n",
        "\n",
        "    res = pandas.DataFrame(res)\n",
        "    print(res)\n",
        "\n",
        "#main()\n",
        "\n",
        "from math import e\n",
        "#a=[0,1,0,1,1,…] = some binary nap set\n",
        "#theorem based on s: p(F(a) = 0) ~= (d/(d+1))^d = e^(-1) as d -> inf.\n",
        "#want to optimize: p(F(a) = 0) ~= e^(−1) ~= t, gradient descend on alpha.\n",
        "#Intuition: alpha高, contains 更多 relus, p(F(a))更高. 所以F(a)是1的时候，descend theta, alpha变小\n",
        "\n",
        "all_relus=60   # |J|\n",
        "n=10 # num samples\n",
        "theta=1\n",
        "step_size=0.1\n",
        "target_prob=e**(-1)\n",
        "F_count=0\n",
        "\n",
        "def get_alpha(theta):\n",
        "  return (1+e**(-theta))**(-1)\n",
        "\n",
        "def F(a):\n",
        "  exit_code=\"error\"\n",
        "  for other_label in range(3):\n",
        "    if other_label == int(label):\n",
        "      continue\n",
        "    try:\n",
        "      exit_code, running_time = check_pattern(STABLE_PATTERNS[label],\n",
        "                                            label=int(label), other_label = other_label, a=a)\n",
        "    except Exception as e:\n",
        "      print(f\"exception {e}\")\n",
        "    if exit_code==\"sat\":\n",
        "      return \"sat\"\n",
        "  return exit_code #0 means robust, good!\n",
        "\n",
        "\n",
        "def sample(alpha, a_L, a_U):\n",
        "  a=a_L.copy()\n",
        "  for j in range(len(a_U)):\n",
        "    if a_U[j]==1 and a_L[j]==0:\n",
        "      a[j]= np.random.choice([0, 1], p=[1-alpha, alpha])#.reshape(n,) #turn on with probability alpha\n",
        "  return a\n",
        "\n",
        "def StatRefine(a_L,theta):\n",
        "  global F_count\n",
        "  print(f\"alpha: {get_alpha(theta)}\")\n",
        "  if F(a_L)==\"unsat\": #or current set(a_L)size太大了及时止损 but adjust alpha now, no need to care for s. In practice, s is unknown, so we seek a mechanism for setting α without this knowledge\n",
        "    return a_L\n",
        "  examples=[] #should alpha be updated inside or outside the loop?\n",
        "  alpha=get_alpha(theta)\n",
        "  for i in range(n): # generate example\n",
        "    larger_set=[1 for i in range(all_relus)]\n",
        "    a_i= sample(alpha, a_L, larger_set)\n",
        "    if F(a_i) == \"unsat\":\n",
        "       F_count+=1\n",
        "       F_a_i = 0\n",
        "    else:\n",
        "       F_count+=1\n",
        "       F_a_i = 1\n",
        "    theta=theta-step_size*(1-F_a_i-target_prob) #If |marabou(a_i)=unsat| is large, decrease alpha (gradient descend??)\n",
        "    examples.append((a_i,F_a_i))\n",
        "\n",
        "  j_count=[0 for i in range(all_relus)]\n",
        "  for j in range(all_relus):\n",
        "    if a_L[j]==0:\n",
        "      for (a_i, F_a_i) in examples:\n",
        "        if a_i[j]==1 and F_a_i==0:\n",
        "          j_count[j]+=1\n",
        "\n",
        "  j_max=np.array(j_count).argmax()\n",
        "  a_L[j_max]=1\n",
        "  return StatRefine(a_L,theta)\n",
        "\n",
        "#run StatRefine\n",
        "a=[0 for i in range(all_relus)]\n",
        "#StatRefine(a,theta)"
      ],
      "metadata": {
        "id": "YAixkQqXlJ8g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "id": "k4FqgMf9ilVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "statrefine"
      ],
      "metadata": {
        "id": "M8hbmAO68A82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theta=1\n",
        "label=1\n",
        "a=[0 for i in range(all_relus)]\n",
        "final_a=StatRefine(a,theta)\n",
        "print(f\"{final_a.count(1)} valid relus for label: {label} = {np.where(np.array(final_a)==1)[0].tolist()}\") #varies from 1 to 7??\n",
        "print(f\"{F_count} calls to F\")"
      ],
      "metadata": {
        "id": "FeGUo014txE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "F_count=0\n",
        "def activecoarsen(a_U,theta):\n",
        "  global F_count\n",
        "  alpha=get_alpha(theta)\n",
        "  if alpha<e**(-1) and F(a_U)==\"unsat\":#a_U.count(1)<=10:\n",
        "    return a_U#scancorasen(empty,a_U)\n",
        "  empty=[0 for i in range(all_relus)]\n",
        "  a=sample(alpha,empty,a_U)\n",
        "  if F(a)==\"unsat\":\n",
        "    F_count+=1\n",
        "    F_a_i = 0\n",
        "    theta=theta-step_size*(1-F_a_i-target_prob)\n",
        "    return activecoarsen(a,theta) #reduced\n",
        "  else:\n",
        "    F_count+=1\n",
        "    F_a_i = 1\n",
        "    theta=theta-step_size*(1-F_a_i-target_prob)\n",
        "    return activecoarsen(a_U,theta) #try again"
      ],
      "metadata": {
        "id": "YetCxoOk4igr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "active coarsen"
      ],
      "metadata": {
        "id": "THFfL_Y08DF1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theta=1\n",
        "label=0\n",
        "final_a=activecoarsen([1 for i in range(all_relus)],theta)\n",
        "print(f\"valid relu for label {label}: {final_a.count(1)}, at {np.where(np.array(final_a)==1)[0].tolist()}, calls of F: {F_count}\") #varies from 1 to 7??"
      ],
      "metadata": {
        "id": "BASYVf7_5n_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cscan coarsen\n"
      ],
      "metadata": {
        "id": "GZKad3gr8HWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def func(relus):\n",
        "    for other_label in range(3):\n",
        "        exit_code, running_time = check_pattern(relus, label=int(label), other_label=other_label)\n",
        "        if exit_code == \"sat\":\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "def scancoarsen(relu_label):\n",
        "    keys = list(relu_label.keys())  # Convert keys to a list to avoid runtime error while modifying the dictionary\n",
        "    for k in keys:\n",
        "        print(f\"consider neuron={k}\")\n",
        "        vals = relu_label[k]\n",
        "        relu_label_copy = relu_label.copy()\n",
        "        relu_label_copy.pop(k)\n",
        "        if func(relu_label_copy):\n",
        "            relu_label.pop(k)\n",
        "            print(relu_label.keys())\n",
        "            continue\n",
        "        else:\n",
        "            relu_label[k] = vals\n",
        "    return list(relu_label.keys())  # Return the remaining keys\n",
        "\n",
        "# # Assuming STABLE_PATTERNS is a list of dictionaries\n",
        "# for label in range(1):\n",
        "#     relu_label = STABLE_PATTERNS[label].copy()\n",
        "#     remaining_keys = scancoarsen(relu_label)\n",
        "#     print(f\"Remaining keys after coarsening for label {label}: {remaining_keys}\")\n",
        "\n",
        "relu_remaining={}\n",
        "for label in [0,1,2]:\n",
        "  relu_label = STABLE_PATTERNS[label].copy()\n",
        "  remaining_keys = scancoarsen(relu_label)\n",
        "  relu_remaining[label]=remaining_keys\n",
        "\n",
        "for k,v in relu_remaining.items():\n",
        "  print(f\"Remaining keys after coarsening for label {k}: {v}\") #wow colab ai code is really good!\n",
        "#print(f\"Remaining keys after coarsening for label {label}: {remaining_keys}\")"
      ],
      "metadata": {
        "id": "kc6VsxRc1J4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **If marabou doesn't work, try the following code to see where the algorithm crashed. **"
      ],
      "metadata": {
        "id": "h4InMsox8KiJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network=init_network()\n",
        "offset = network.outputVars[0][0][0]\n",
        "label=0\n",
        "other_label=1\n",
        "#add constraint\n",
        "for i in range(4):\n",
        "  network.setLowerBound(i, 0)\n",
        "  network.setUpperBound(i, 1)\n",
        "#add output constraint\n",
        "#why not just add all other labels??\n",
        "constraint = MarabouUtils.Equation(MarabouCore.Equation.GE)\n",
        "constraint.addAddend(1, other_label+offset)\n",
        "constraint.addAddend(-1, label+offset)\n",
        "constraint.setScalar(0.001)\n",
        "network.addEquation(constraint)\n",
        "\n",
        "for neuron,values in STABLE_PATTERNS[label].items(): #everything\n",
        "  if a[neuron]==1: #include this relu\n",
        "    layer, idx, marabou_idx = parse_raw_idx(neuron)\n",
        "    #print(f'{neuron}: {values}')\n",
        "    if values.count(0) > len(values)*0.5: #len(X_train)*0.5:  len(values)\n",
        "        constraint = MarabouUtils.Equation(MarabouCore.Equation.LE)\n",
        "        constraint.addAddend(1, marabou_idx)\n",
        "        constraint.setScalar(-0.001)\n",
        "    else:\n",
        "        constraint = MarabouUtils.Equation(MarabouCore.Equation.GE)\n",
        "        constraint.addAddend(1, marabou_idx)\n",
        "        constraint.setScalar(0.001)\n",
        "    network.addEquation(constraint)\n",
        "\n",
        "#import pdb;pdb.set_trace()\n",
        "\n",
        "try:\n",
        "  exit_code, vals, stats = network.solve(options=M_OPTIONS)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  print(exit_code)\n",
        "\n",
        "#exit_code, vals, stats = network.solve(options=M_OPTIONS)\n",
        "# print(exit_code)\n",
        "# print(val)\n",
        "#len(network.equList)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-wkDo3Dr5zg",
        "outputId": "4a620e34-4572-4344-d281-0723f5af85bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unsat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Some extra code that doesn't need to be run"
      ],
      "metadata": {
        "id": "g_PiTbeefLV7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M98VjGpkwzeN",
        "outputId": "bf4d84cb-dc1a-41db-96b4-4af0fa0b8798",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10, Loss: 0.6957077980041504\n",
            "Epoch 20, Loss: 0.3569485545158386\n",
            "Epoch 30, Loss: 0.06546592712402344\n",
            "Epoch 40, Loss: 0.14150819182395935\n",
            "Epoch 50, Loss: 0.08709496259689331\n",
            "Epoch 60, Loss: 0.005371565464884043\n",
            "Epoch 70, Loss: 0.03119882568717003\n",
            "Epoch 80, Loss: 0.001806743093766272\n",
            "Epoch 90, Loss: 0.0013030058471485972\n",
            "Epoch 100, Loss: 0.003509345930069685\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load the Iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "# Define the neural network architecture\n",
        "class IrisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IrisNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 20)  # Input layer to hidden layer\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(20, 20) # Hidden layer to hidden layer\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(20, 20) # Hidden layer to hidden layer\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc4 = nn.Linear(20, 3)  # Hidden layer to output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "# Initialize the network\n",
        "model = IrisNet()\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "epochs = 100\n",
        "for epoch in range(epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Print loss every 10 epochs\n",
        "    if epoch % 10 == 9:\n",
        "        print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "# Check if the model trains without error up to this point\n",
        "# \"Model trained successfully!\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqDgTtJARaCI",
        "outputId": "ca02ca74-4821-43c8-8fc9-83b9873f921d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'relu1': tensor([[1.2062, 1.4942, 0.0000, 2.6629, 0.0000, 0.0000, 0.1008, 0.0000, 1.2812,\n",
              "          0.4878, 1.9803, 1.7296, 2.2217, 1.8856, 0.0000, 0.0000, 1.3994, 0.0000,\n",
              "          0.0000, 2.1766]]),\n",
              " 'relu2': tensor([[3.5583e+00, 0.0000e+00, 4.5825e+00, 0.0000e+00, 3.0476e+00, 3.5773e+00,\n",
              "          0.0000e+00, 0.0000e+00, 3.5550e+00, 3.8430e+00, 0.0000e+00, 0.0000e+00,\n",
              "          0.0000e+00, 0.0000e+00, 0.0000e+00, 4.2207e+00, 3.7258e+00, 5.4662e+00,\n",
              "          0.0000e+00, 1.4705e-03]]),\n",
              " 'relu3': tensor([[ 0.0000,  0.0000,  0.0000,  2.0140,  0.0000,  3.8408,  0.0000,  0.0000,\n",
              "           3.7716,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, 10.4726,  8.1664,\n",
              "           0.0000,  0.0000,  8.5828,  0.0000]])}"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import onnx\n",
        "from onnx2pytorch import ConvertModel\n",
        "\n",
        "\n",
        "# onnx_model = onnx.load(\"iris_model.onnx\")\n",
        "# model = ConvertModel(onnx_model)\n",
        "\n",
        "activations = {}\n",
        "\n",
        "def get_activation(name):\n",
        "    def hook(model, input, output):\n",
        "        activations[name] = output.detach()\n",
        "    return hook\n",
        "\n",
        "i=1\n",
        "# Assuming the ReLU layers are named similarly to your PyTorch model, you can add hooks like this\n",
        "for name, layer in model.named_modules():\n",
        "    if isinstance(layer, torch.nn.ReLU):\n",
        "        # Register the hook\n",
        "        layer.register_forward_hook(get_activation(f'relu{i}'))\n",
        "        i=i+1\n",
        "\n",
        "# Now, when you run a forward pass, the hooks will store the ReLU activations\n",
        "with torch.no_grad():\n",
        "    output = model(X_train_tensor[0].unsqueeze(0))\n",
        "\n",
        "# Check the captured activations\n",
        "activations\n",
        "# Remove hooks (to clean up)\n",
        "# hook1.remove()\n",
        "# hook2.remove()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZaXSAFSh5Nu",
        "outputId": "5c0773aa-d716-4291-e12e-f6e9adbb23da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30/30\n"
          ]
        }
      ],
      "source": [
        "#accuracy:\n",
        "i=0\n",
        "with torch.no_grad():\n",
        "  for inputs,label in zip(X_test_tensor, y_test_tensor):\n",
        "          outputs = model(inputs.unsqueeze(0))\n",
        "          #print(outputs)\n",
        "          pred=outputs.argmax() #output not normalized\n",
        "          if pred==label:\n",
        "            i=i+1\n",
        "print(f'{i}/{len(X_test_tensor)}')\n",
        "\n",
        "model(X_train_tensor[0].unsqueeze(0))\n",
        "\n",
        "onnx_file_path = \"iris_model_60.onnx\"\n",
        "torch.onnx.export(model, torch.randn(1, 4), onnx_file_path, verbose=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8IRdRkQ-pOl"
      },
      "source": [
        "find states:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkaVL6lNSVwH"
      },
      "outputs": [],
      "source": [
        "states={}\n",
        "for i in range(3):\n",
        "  states[i]={}\n",
        "\n",
        "with torch.no_grad():\n",
        "  for neuron in range(60):\n",
        "    for idx, (inputs, labels) in enumerate(train_loader):\n",
        "      for i,t in zip(inputs,labels):\n",
        "        t=t.item()\n",
        "        outputs = model(i.unsqueeze(0))\n",
        "        out=activations[f'relu{(neuron//20)+1}'][:,neuron%20].tolist()[0]\n",
        "        if not neuron in states[t]:\n",
        "          states[t][neuron]=[]\n",
        "        states[t][neuron].append(out)\n",
        "\n",
        "with open(\"relu_states\", \"w\") as fp:\n",
        "  json.dump(states, fp)\n",
        "\n",
        "states[0]\n",
        "\n",
        "# states\n",
        "# json\n",
        "# label:{{neuron: states}, }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeGQse17-vrY"
      },
      "source": [
        "###### initialize marabou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U66qhU6wLW55"
      },
      "outputs": [],
      "source": [
        "#start with all relu，删减直到不能verify？"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hiBON9ZMEL-"
      },
      "outputs": [],
      "source": [
        "# network=init_network()\n",
        "# network.outputVars #4,5,6\n",
        "# network.inputVars #0,1,2,3\n",
        "# network.reluList #(i+10) for i in range(7,37)\n",
        "# network.numVars #47\n",
        "# offset=7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ts3oMryVSutC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgG40QhIS2rs"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}